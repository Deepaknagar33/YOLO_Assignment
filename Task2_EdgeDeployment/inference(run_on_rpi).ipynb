{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1a11dd",
   "metadata": {},
   "source": [
    "### ðŸ§  Inference Script for Parking Slot Detection using ONNX + OpenCV\n",
    "\n",
    "This script performs the following steps:\n",
    "\n",
    "1. **Model and Image Setup**\n",
    "   - Loads a YOLOv8 ONNX model from a specified path.\n",
    "   - Reads and resizes a test image to `640x640` for inference.\n",
    "\n",
    "2. **Dual Logging Setup**\n",
    "   - All outputs are logged both to the terminal and a log file named `inference_log.txt`.\n",
    "\n",
    "3. **ONNX Inference**\n",
    "   - Runs the model on the image using `onnxruntime`.\n",
    "   - Measures and logs FPS (Frames Per Second), CPU usage, and GPU memory usage using `psutil` and `GPUtil`.\n",
    "\n",
    "4. **Postprocessing**\n",
    "   - Parses the output to extract bounding boxes, confidence scores, and class IDs.\n",
    "   - Scales the boxes back to the original image size.\n",
    "   - Filters predictions based on a confidence threshold (`CONF_THRESH = 0.25`).\n",
    "\n",
    "5. **Visualization**\n",
    "   - Draws bounding boxes and class labels (`space-empty` or `space-occupied`) on the original image.\n",
    "   - Saves the annotated image as `output.jpg`.\n",
    "\n",
    "6. **Slot Counting**\n",
    "   - Counts the number of detected empty and occupied parking slots.\n",
    "   - Displays the counts and logs them.\n",
    "\n",
    "7. **Log File Output**\n",
    "   - All printed information is saved to `inference_log.txt`.\n",
    "\n",
    "This script is useful for testing YOLOv8 ONNX models and logging system performance metrics during inference. It helps in evaluating edge deployment readiness and detection quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e11db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting Inference\n",
      "\n",
      "Model: /home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx\n",
      "Image: /home/user/YOLO_Assignment/Task_2/sample_inputs/2012-12-22_13_20_09_jpg.rf.8fa5f4f25da5d974c608cbe84afbc9e6.jpg\n",
      "\n",
      " FPS: 13.39\n",
      "CPU Usage: 2.3%\n",
      "GPU: Quadro RTX 5000, Used: 46.0MB / 16384.0MB\n",
      "\n",
      " Saved annotated output image as 'output.jpg'\n",
      "\n",
      " Parking Slot Counts:\n",
      "  Empty Slots    : 26\n",
      "  Occupied Slots : 1\n",
      "\n",
      " All done. Log saved to inference_log.txt\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "import GPUtil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# === CONFIG ===\n",
    "ONNX_PATH = \"/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx\"\n",
    "IMG_PATH = \"/home/user/YOLO_Assignment/Task_2/sample_inputs/2012-12-22_13_20_09_jpg.rf.8fa5f4f25da5d974c608cbe84afbc9e6.jpg\"\n",
    "CLASS_NAMES = ['space-empty', 'space-occupied']\n",
    "CONF_THRESH = 0.25\n",
    "LOG_FILE = \"inference_log.txt\"\n",
    "\n",
    "# === SETUP DUAL LOGGING ===\n",
    "class Logger:\n",
    "    def __init__(self, filepath):\n",
    "        self.terminal = sys.__stdout__\n",
    "        self.log = open(filepath, \"w\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = Logger(LOG_FILE)\n",
    "\n",
    "# === BEGIN ===\n",
    "print(\"ðŸš€ Starting Inference\\n\")\n",
    "print(f\"Model: {ONNX_PATH}\")\n",
    "print(f\"Image: {IMG_PATH}\")\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "assert os.path.exists(ONNX_PATH), f\"Model not found: {ONNX_PATH}\"\n",
    "session = ort.InferenceSession(ONNX_PATH)\n",
    "\n",
    "# === PREPROCESS IMAGE ===\n",
    "orig_img = cv2.imread(IMG_PATH)\n",
    "resized_img = cv2.resize(orig_img, (640, 640))\n",
    "img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "img_rgb /= 255.0\n",
    "img_rgb = np.transpose(img_rgb, (2, 0, 1))[np.newaxis, ...]\n",
    "\n",
    "# === INFERENCE ===\n",
    "start = time.time()\n",
    "outputs = session.run(None, {\"images\": img_rgb.astype(np.float32)})\n",
    "end = time.time()\n",
    "\n",
    "# === PERFORMANCE ===\n",
    "fps = 1 / (end - start)\n",
    "print(f\"\\n FPS: {fps:.2f}\")\n",
    "print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "for gpu in GPUtil.getGPUs():\n",
    "    print(f\"GPU: {gpu.name}, Used: {gpu.memoryUsed}MB / {gpu.memoryTotal}MB\")\n",
    "\n",
    "# === POSTPROCESS ===\n",
    "detections = outputs[0][0]\n",
    "boxes = []\n",
    "slot_counts = {'space-empty': 0, 'space-occupied': 0}\n",
    "\n",
    "for det in detections:\n",
    "    x1, y1, x2, y2, conf, cls = det\n",
    "    if conf < CONF_THRESH:\n",
    "        continue\n",
    "    x1 = int(x1 * orig_img.shape[1] / 640)\n",
    "    y1 = int(y1 * orig_img.shape[0] / 640)\n",
    "    x2 = int(x2 * orig_img.shape[1] / 640)\n",
    "    y2 = int(y2 * orig_img.shape[0] / 640)\n",
    "    cls_id = int(cls)\n",
    "    boxes.append((x1, y1, x2, y2, float(conf), cls_id))\n",
    "    slot_counts[CLASS_NAMES[cls_id]] += 1\n",
    "\n",
    "# === DRAW ===\n",
    "for x1, y1, x2, y2, conf, cls_id in boxes:\n",
    "    label = f\"{CLASS_NAMES[cls_id]}: {conf:.2f}\"\n",
    "    cv2.rectangle(orig_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(orig_img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite(\"output.jpg\", orig_img)\n",
    "print(\"\\n Saved annotated output image as 'output.jpg'\")\n",
    "\n",
    "# === COUNTS ===\n",
    "print(\"\\n Parking Slot Counts:\")\n",
    "print(f\"  Empty Slots    : {slot_counts['space-empty']}\")\n",
    "print(f\"  Occupied Slots : {slot_counts['space-occupied']}\")\n",
    "\n",
    "# === CLOSE LOG ===\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.__stdout__\n",
    "print(\"\\n All done. Log saved to inference_log.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70b2ed",
   "metadata": {},
   "source": [
    "### ðŸ“ Output Resources on Google Drive\n",
    "\n",
    "Below are the links to various output folders stored on Google Drive:\n",
    "\n",
    "- ðŸ“„ **Inference Logs**:  \n",
    "  Contains system logs, FPS, CPU/GPU usage, and slot counts per image/video.  \n",
    "  ðŸ”— [Open inference_logs folder](https://drive.google.com/drive/folders/1od03HzUF7iAwpSf-_z77dke_-ShzL_yY?usp=sharing)\n",
    "\n",
    "- ðŸŽ¥ **Sample Video Output**:  \n",
    "  Contains video clips with annotated bounding boxes for occupied and empty parking slots.  \n",
    "  ðŸ”— [Open sample_video_output folder](https://drive.google.com/drive/folders/1VpYMTd6B6tLJEJUlPzjvI9kebkD85RmC?usp=sharing)\n",
    "\n",
    "- ðŸ–¼ï¸ **Sample Image Output**:  \n",
    "  Contains processed images with bounding boxes and class labels.  \n",
    "  ðŸ”— [Open sample_image_output folder](https://drive.google.com/drive/folders/1xYDqrI5ZoaziP1mYRBHt8_0OPY6_Q2CZ?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000aec45",
   "metadata": {},
   "source": [
    "### âœ… Inference Results Summary\n",
    "\n",
    "**ðŸ–¼ï¸ Input Image**:  \n",
    "`2012-12-22_13_20_09_jpg.rf.8fa5f4f25da5d974c608cbe84afbc9e6.jpg`  \n",
    "\n",
    "**ðŸ’¾ Output**:  \n",
    "Annotated image saved as: `output.jpg`\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ“Š Detection Summary**:\n",
    "- **Empty Slots**: `26`\n",
    "- **Occupied Slots**: `1`\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸ–¥ï¸ System Performance**:\n",
    "- **FPS (Frames Per Second)**: `13.47`\n",
    "- **CPU Usage**: `0.2%`\n",
    "- **GPU**: Quadro RTX 5000  \n",
    "  â†’ **Memory Used**: `46.0MB` / `16384.0MB`\n",
    "\n",
    "---\n",
    "\n",
    "This result confirms successful inference on the uploaded parking lot image with low resource usage and accurate slot classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683c2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
