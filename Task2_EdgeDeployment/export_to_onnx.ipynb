{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efac1839",
   "metadata": {},
   "source": [
    "### üîÑ Exporting YOLOv8 Model to ONNX Format\n",
    "\n",
    "The following code exports a trained YOLOv8 model (`best.pt`) to ONNX format with proper postprocessing enabled (NMS, confidence thresholding, and class decoding):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cb6779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.151 üöÄ Python-3.11.9 torch-2.5.1 CPU (Intel Xeon Gold 5117 2.00GHz)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.57...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 4.0s, saved as '/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (5.2s)\n",
      "Results saved to \u001b[1m/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx imgsz=640 data=/home/user/YOLO_Assignment/Task_1/Dataset/dataset_yolo/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.pt\")\n",
    "\n",
    "#  Important: Enable postprocessing by setting `nms=True` (enabled by default from v8.1)\n",
    "model.export(format=\"onnx\", imgsz=640, dynamic=True, simplify=True, opset=12,nms=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08fd99",
   "metadata": {},
   "source": [
    "### ‚úÖ ONNX Model Validation\n",
    "\n",
    "The following code is used to **validate the structure and integrity** of the exported YOLOv8 ONNX model:\n",
    "\n",
    "```python\n",
    "import onnx\n",
    "\n",
    "# Load the model from disk\n",
    "model = onnx.load('/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx')\n",
    "\n",
    "# Run structural checks on the model\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "print(\"‚úÖ ONNX model is valid!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7377a56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ONNX model is valid!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the model\n",
    "model = onnx.load('/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx')\n",
    "\n",
    "# Check if the model is valid\n",
    "onnx.checker.check_model(model)\n",
    "print(\" ONNX model is valid!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d947b",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Dynamic Quantization of YOLOv8 ONNX Model\n",
    "\n",
    "The following code applies **dynamic quantization** to the exported YOLOv8 ONNX model to reduce model size and improve inference efficiency:\n",
    "\n",
    "```python\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# Input & Output Paths\n",
    "input_model = \"/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx\"\n",
    "quantized_model = \"best_quantized.onnx\"\n",
    "\n",
    "# Apply Dynamic Quantization\n",
    "quantize_dynamic(\n",
    "    model_input=input_model,\n",
    "    model_output=quantized_model,\n",
    "    weight_type=QuantType.QInt8  # Or use QuantType.QUInt8\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Quantization complete. Saved as:\", quantized_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4feb2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Quantization complete. Saved as: best_quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# Input & Output Paths\n",
    "input_model = \"/home/user/YOLO_Assignment/Task_1/Model/runs_train_val/detect/yolov8_parking/weights/best.onnx\"\n",
    "quantized_model = \"best_quantized.onnx\"\n",
    "\n",
    "# Apply Dynamic Quantization\n",
    "quantize_dynamic(\n",
    "    model_input=input_model,\n",
    "    model_output=quantized_model,\n",
    "    weight_type=QuantType.QInt8  # Or use QuantType.QUInt8\n",
    ")\n",
    "\n",
    "print(\" Quantization complete. Saved as:\", quantized_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccbafb",
   "metadata": {},
   "source": [
    "### üì¶ YOLOv8 Model Weights (Google Drive)\n",
    "\n",
    "You can download the trained YOLOv8 model weights (`best.pt`, `best.onnx` and  `best_quantized.onnx`) from the following shared Google Drive folder:\n",
    "\n",
    "üîó [Download YOLOv8 Weights](https://drive.google.com/drive/folders/1LfwMxtaqUxWGQxqFh6PKw3O1rZN8ohAV?usp=sharing)\n",
    "\n",
    "---\n",
    "\n",
    "**Contents of the Folder:**\n",
    "- `best.pt`: Original PyTorch model (for Ultralytics API usage and re-exporting)\n",
    "- `best.onnx`: Exported ONNX model with postprocessing (NMS) enabled\n",
    "- `best_quantized.onnx`: Dynamically quantized ONNX model for efficient deployment\n",
    "\n",
    "Please make sure to **replace `your_folder_id_here`** with the actual Google Drive folder ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9d15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
